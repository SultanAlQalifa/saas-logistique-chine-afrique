import OpenAI from 'openai'

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface ChatCompletionOptions {
  model?: string
  temperature?: number
  maxTokens?: number
  systemPrompt?: string
}

// Fonction pour r√©cup√©rer la configuration IA depuis l'API
async function getAIConfig() {
  try {
    // Try to get config from ConfigManager first (server-side)
    if (typeof window === 'undefined') {
      try {
        const { ConfigManager } = await import('@/lib/config-manager')
        const config = await ConfigManager.getAIConfig()
        if (config) {
          console.log('Configuration IA r√©cup√©r√©e via ConfigManager:', { hasApiKey: !!config.openaiApiKey })
          return config
        }
      } catch (error) {
        console.warn('Erreur lors de la r√©cup√©ration via ConfigManager:', error)
      }
    }

    // Fallback to API call
    const baseUrl = process.env.NEXTAUTH_URL || 'http://localhost:3000'
    const response = await fetch(`${baseUrl}/api/ai-config`, {
      headers: {
        'Content-Type': 'application/json',
      }
    })
    
    if (response.ok) {
      const data = await response.json()
      console.log('Configuration IA r√©cup√©r√©e via API:', data)
      return data.config
    } else {
      console.warn('Erreur HTTP lors de la r√©cup√©ration de la config IA:', response.status)
    }
  } catch (error) {
    console.warn('Impossible de r√©cup√©rer la configuration IA:', error)
  }
  
  // Return default config with environment variable
  const envApiKey = process.env.OPENAI_API_KEY
  return {
    openaiApiKey: envApiKey && envApiKey.startsWith('sk-') ? envApiKey : '',
    gpt5Enabled: true,
    gpt5Model: 'gpt-4o',
    maxTokens: 4096,
    temperature: 0.7,
    systemPrompt: 'Vous √™tes un assistant IA sp√©cialis√© en logistique Chine-Afrique.',
    autoResponse: true,
    responseDelay: 1000,
    fallbackModel: 'gpt-4o',
    contextWindow: 128000,
    streamingEnabled: true
  }
}

export class OpenAIService {
  private static instance: OpenAIService
  private client: OpenAI | null | string

  private constructor() {
    this.client = null
    this.initializeClient()
  }

  private async initializeClient() {
    const config = await getAIConfig()
    console.log('Initialisation client OpenAI avec config:', config) // Debug
    if (config.openaiApiKey && config.openaiApiKey !== '' && config.openaiApiKey.startsWith('sk-')) {
      try {
        this.client = new OpenAI({ apiKey: config.openaiApiKey })
        console.log('Client OpenAI initialis√© avec succ√®s') // Debug
      } catch (error) {
        console.error('Erreur lors de l\'initialisation du client OpenAI:', error)
        this.client = null
      }
    } else {
      console.warn('Cl√© API OpenAI manquante ou invalide:', config.openaiApiKey) // Debug
    }
  }

  public static getInstance(): OpenAIService {
    if (!OpenAIService.instance) {
      OpenAIService.instance = new OpenAIService()
    }
    return OpenAIService.instance
  }

  // M√©thode pour r√©initialiser le client avec une nouvelle cl√© API
  public async updateApiKey(apiKey: string) {
    if (apiKey && apiKey.startsWith('sk-')) {
      try {
        this.client = new OpenAI({ apiKey })
        console.log('Client OpenAI mis √† jour avec nouvelle cl√© API')
        return true
      } catch (error) {
        console.error('Erreur lors de la mise √† jour de la cl√© API:', error)
        this.client = null
        return false
      }
    }
    return false
  }

  /**
   * Generate a chat completion using OpenAI GPT
   */
  async generateChatCompletion(
    messages: ChatMessage[],
    options: ChatCompletionOptions = {}
  ): Promise<string> {
    if (!this.client) {
      return this.generateProductionResponse(messages[messages.length - 1]?.content || '')
    }
    
    // V√©rifier si le client est initialis√©
    if (!this.client || typeof this.client === 'string') {
      return this.generateProductionResponse(messages[messages.length - 1]?.content || '')
    }
    
    try {
      const {
        model = 'gpt-4o',
        temperature = 0.7,
        maxTokens = 1000,
        systemPrompt
      } = options

      // Add system prompt if provided
      const finalMessages: ChatMessage[] = systemPrompt
        ? [{ role: 'system', content: systemPrompt }, ...messages]
        : messages

      const completion = await (this.client as OpenAI).chat.completions.create({
        model,
        messages: finalMessages,
        temperature,
        max_tokens: maxTokens,
        stream: false,
      })

      return completion.choices[0]?.message?.content || 'D√©sol√©, je n\'ai pas pu g√©n√©rer une r√©ponse.'
    } catch (error) {
      console.error('OpenAI API Error:', error)
      
      // En cas d'erreur API (rate limit, mod√®le indisponible, etc.), utiliser les r√©ponses de production
      const userMessage = messages[messages.length - 1]?.content || ''
      console.log('Fallback vers r√©ponses de production pour:', userMessage)
      return this.generateProductionResponse(userMessage)
    }
  }

  /**
   * Generate production-ready streaming fallback for when OpenAI API is unavailable
   */
  private async *generateProductionStreamingFallback(userMessage: string): AsyncIterable<string> {
    const response = this.generateProductionResponse(userMessage)
    const words = response.split(' ')
    
    for (let i = 0; i < words.length; i++) {
      const chunk = i === 0 ? words[i] : ' ' + words[i]
      yield chunk
      // Simulate typing delay
      await new Promise(resolve => setTimeout(resolve, 50))
    }
  }

  private generateProductionResponse(userMessage: string): string {
    const lowerMessage = userMessage.toLowerCase().trim()
    
    // Messages tr√®s courts (cc, ok, etc.)
    if (lowerMessage.match(/^(cc|ok|d'accord|oui|non|merci|thanks)$/)) {
      return 'üëç **Parfait !**\n\nY a-t-il autre chose que je puisse faire pour vous ?\n\n‚Ä¢ üì¶ V√©rifier un suivi de colis\n‚Ä¢ üí∞ Obtenir un devis\n‚Ä¢ üìû Contacter un agent humain\n‚Ä¢ ‚ùì Poser une question sp√©cifique'
    }
    
    // Salutations
    if (lowerMessage.match(/^(bonjour|salut|hello|hi|bonsoir|cv|√ßa va|comment allez-vous)$/)) {
      return 'üëã **Bonjour !** Je suis votre assistant NextMove Cargo.\n\nüéØ **Comment puis-je vous aider aujourd\'hui ?**\n\n‚Ä¢ üì¶ **Suivi de colis** - V√©rifiez o√π se trouve votre envoi\n‚Ä¢ üí∞ **Devis personnalis√©** - Calculez vos frais de transport\n‚Ä¢ ‚è∞ **D√©lais de livraison** - Planifiez vos exp√©ditions\n‚Ä¢ üìã **Documentation** - Pr√©parez vos papiers d\'exportation\n‚Ä¢ üåç **Zones couvertes** - D√©couvrez nos destinations\n\nTapez simplement votre question ou choisissez un sujet !'
    }
    
    // Suivi de colis
    if (lowerMessage.includes('suivi') || lowerMessage.includes('track') || lowerMessage.includes('colis') || lowerMessage.includes('co-')) {
      return 'üöö **Suivi de colis NextMove Cargo**\n\nPour suivre votre colis :\n\n1Ô∏è‚É£ **Saisissez votre num√©ro** (ex: CO-001234)\n2Ô∏è‚É£ **Consultez le statut** en temps r√©el\n3Ô∏è‚É£ **Recevez des notifications** automatiques\n\nüìç **Statuts possibles** :\n‚Ä¢ En pr√©paration (Chine)\n‚Ä¢ Exp√©di√© (en transit)\n‚Ä¢ Arriv√© au port (d√©douanement)\n‚Ä¢ En livraison\n‚Ä¢ Livr√©\n\nüí° Donnez-moi votre num√©ro de suivi pour plus de d√©tails !'
    }
    
    // Tarifs et prix
    if (lowerMessage.includes('tarif') || lowerMessage.includes('prix') || lowerMessage.includes('co√ªt') || lowerMessage.includes('devis')) {
      return 'üí∞ **Tarification NextMove Cargo**\n\nüìä **Facteurs de prix** :\n‚Ä¢ Poids et dimensions\n‚Ä¢ Destination en Afrique\n‚Ä¢ Mode de transport\n‚Ä¢ Services additionnels\n\nüö¢ **Maritime** (√©conomique) :\n‚Ä¢ 5kg ‚Üí S√©n√©gal : 25 000 FCFA\n‚Ä¢ 10kg ‚Üí C√¥te d\'Ivoire : 35 000 FCFA\n‚Ä¢ 20kg ‚Üí Mali : 55 000 FCFA\n\n‚úàÔ∏è **A√©rien** (rapide) :\n‚Ä¢ 5kg ‚Üí S√©n√©gal : 45 000 FCFA\n‚Ä¢ 10kg ‚Üí C√¥te d\'Ivoire : 75 000 FCFA\n\nüéØ **Demandez un devis personnalis√©** pour vos besoins sp√©cifiques !'
    }
    
    // D√©lais de livraison
    if (lowerMessage.includes('d√©lai') || lowerMessage.includes('livraison') || lowerMessage.includes('temps') || lowerMessage.includes('combien')) {
      return '‚è∞ **D√©lais de livraison NextMove Cargo**\n\nüö¢ **Transport Maritime** :\n‚Ä¢ Chine ‚Üí S√©n√©gal : 20-25 jours\n‚Ä¢ Chine ‚Üí C√¥te d\'Ivoire : 22-27 jours\n‚Ä¢ Chine ‚Üí Mali : 25-30 jours\n‚Ä¢ Chine ‚Üí Burkina Faso : 25-30 jours\n\n‚úàÔ∏è **Transport A√©rien** :\n‚Ä¢ Chine ‚Üí S√©n√©gal : 5-7 jours\n‚Ä¢ Chine ‚Üí C√¥te d\'Ivoire : 6-8 jours\n‚Ä¢ Chine ‚Üí Mali : 8-10 jours\n\n‚ö†Ô∏è *D√©lais indicatifs hors formalit√©s douani√®res et jours f√©ri√©s*'
    }
    
    // Documentation
    if (lowerMessage.includes('document') || lowerMessage.includes('douane') || lowerMessage.includes('papier') || lowerMessage.includes('formalit√©')) {
      return 'üìã **Documents requis - NextMove Cargo**\n\nüì§ **Pour exp√©dier depuis la Chine** :\n‚Ä¢ Facture commerciale (en anglais)\n‚Ä¢ Liste de colisage d√©taill√©e\n‚Ä¢ Certificat d\'origine (si requis)\n‚Ä¢ D√©claration de valeur\n‚Ä¢ Photos des produits\n\nüì• **Pour r√©ceptionner en Afrique** :\n‚Ä¢ Pi√®ce d\'identit√© valide\n‚Ä¢ Justificatif de domicile r√©cent\n‚Ä¢ Num√©ro de suivi NextMove\n‚Ä¢ Preuve de paiement\n\nü§ù **Notre √©quipe vous accompagne** dans toutes les d√©marches administratives !'
    }
    
    // Contact et support
    if (lowerMessage.includes('contact') || lowerMessage.includes('support') || lowerMessage.includes('aide') || lowerMessage.includes('agent') || lowerMessage.includes('humain')) {
      return 'ü§ù **Support NextMove Cargo**\n\nüìû **T√©l√©phone** : +221 33 123 45 67\n‚è∞ Lun-Ven 8h-18h, Sam 9h-13h\n\nüìß **Email** : support@nextmovecargo.com\n‚ö° R√©ponse sous 2h en moyenne\n\nüí¨ **WhatsApp** : +221 77 123 45 67\nüåç Disponible 24h/24\n\nüë®‚Äçüíº **Souhaitez-vous que je vous transf√®re vers un agent humain ?**'
    }
    
    // Probl√®mes techniques
    if (lowerMessage.includes('probl√®me') || lowerMessage.includes('erreur') || lowerMessage.includes('bug') || lowerMessage.includes('marche pas')) {
      return 'üîß **Support technique NextMove Cargo**\n\nüö® **Probl√®me d√©tect√©** - Je vous aide !\n\nüìù **D√©crivez votre probl√®me** :\n‚Ä¢ Que faisiez-vous ?\n‚Ä¢ Quel message d\'erreur avez-vous vu ?\n‚Ä¢ Sur quelle page ?\n\n‚ö° **Solutions rapides** :\n‚Ä¢ Actualisez la page (F5)\n‚Ä¢ Videz le cache navigateur\n‚Ä¢ V√©rifiez votre connexion\n\nüë®‚Äçüíª **Besoin d\'aide avanc√©e ?** Je peux vous transf√©rer vers notre √©quipe technique.'
    }
    
    return 'ü§ñ **Assistant IA NextMove Cargo**\n\nJe suis l√† pour vous aider avec la logistique Chine-Afrique !\n\nüéØ **Mes sp√©cialit√©s** :\n‚Ä¢ üì¶ Suivi et gestion de colis\n‚Ä¢ üí∞ Calculs tarifaires personnalis√©s\n‚Ä¢ ‚è∞ Planification des d√©lais\n‚Ä¢ üìã Assistance documentaire\n‚Ä¢ üåç Informations sur nos zones\n\nüí° **Astuce** : Soyez sp√©cifique dans vos questions pour obtenir une aide personnalis√©e !\n\n‚ùì **Que puis-je faire pour vous aujourd\'hui ?**'
  }

  /**
   * Generate a streaming chat completion
   */
  async generateStreamingCompletion(
    messages: ChatMessage[],
    options: ChatCompletionOptions = {}
  ): Promise<AsyncIterable<string>> {
    if (!this.client) {
      // Fallback pour streaming : retourner la r√©ponse de production en chunks
      return this.generateProductionStreamingFallback(messages[messages.length - 1]?.content || '')
    }
    
    try {
      const {
        model = 'gpt-4o',
        temperature = 0.7,
        maxTokens = 1000,
        systemPrompt
      } = options

      const finalMessages: ChatMessage[] = systemPrompt
        ? [{ role: 'system', content: systemPrompt }, ...messages]
        : messages

      const stream = await (this.client as OpenAI).chat.completions.create({
        model,
        messages: finalMessages,
        temperature,
        max_tokens: maxTokens,
        stream: true,
      })

      return this.processStream(stream)
    } catch (error) {
      console.error('OpenAI Streaming Error:', error)
      throw new Error('Erreur lors de la g√©n√©ration de la r√©ponse en streaming')
    }
  }

  private async * processStream(stream: any): AsyncIterable<string> {
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content
      if (content) {
        yield content
      }
    }
  }

  /**
   * Generate logistics-specific responses
   */
  async generateLogisticsResponse(
    userMessage: string,
    context?: string
  ): Promise<string> {
    if (!this.client) {
      return this.generateProductionResponse(userMessage)
    }
    const systemPrompt = `Tu es un assistant IA sp√©cialis√© dans la logistique entre la Chine et l'Afrique pour NextMove Cargo. 
    
    Contexte de l'entreprise:
    - NextMove Cargo est une plateforme SaaS de logistique
    - Sp√©cialis√©e dans les √©changes commerciaux Chine-Afrique
    - Services: suivi de colis, gestion des exp√©ditions, documentation douani√®re
    - Zones couvertes: Afrique de l'Ouest et Centrale, principalement depuis la Chine
    
    Instructions:
    - R√©ponds en fran√ßais
    - Sois professionnel mais accessible
    - Fournis des informations pr√©cises sur la logistique
    - Propose des solutions concr√®tes
    - Mentionne les services NextMove Cargo quand pertinent
    - Si tu ne connais pas une information sp√©cifique, recommande de contacter le support
    
    ${context ? `Contexte suppl√©mentaire: ${context}` : ''}`

    const messages: ChatMessage[] = [
      { role: 'user', content: userMessage }
    ]

    try {
      return await this.generateChatCompletion(messages, {
        systemPrompt,
        temperature: 0.7,
        maxTokens: 800
      })
    } catch (error) {
      console.error('Erreur g√©n√©ration r√©ponse logistique:', error)
      return this.generateProductionResponse(userMessage)
    }
  }

  /**
   * Generate FAQ responses
   */
  async generateFAQResponse(
    question: string,
    category?: string
  ): Promise<string> {
    if (!this.client) {
      return this.generateProductionResponse(question)
    }
    const systemPrompt = `Tu es un assistant pour la FAQ de NextMove Cargo. 
    
    R√©ponds aux questions fr√©quentes sur:
    - Suivi de colis
    - D√©lais de livraison
    - Frais de transport
    - Documentation n√©cessaire
    - Processus d'exp√©dition
    - Zones de couverture
    
    Sois concis, pr√©cis et utile. Fournis des √©tapes claires quand n√©cessaire.
    ${category ? `Cat√©gorie de la question: ${category}` : ''}`

    const messages: ChatMessage[] = [
      { role: 'user', content: question }
    ]

    try {
      return await this.generateChatCompletion(messages, {
        systemPrompt,
        temperature: 0.5,
        maxTokens: 500
      })
    } catch (error) {
      console.error('Erreur g√©n√©ration r√©ponse FAQ:', error)
      return this.generateProductionResponse(question)
    }
  }

  /**
   * Analyze and categorize user messages
   */
  async categorizeMessage(message: string): Promise<{
    category: string
    intent: string
    confidence: number
  }> {
    if (!this.client) {
      return {
        category: 'general',
        intent: 'unknown',
        confidence: 0
      }
    }
    const systemPrompt = `Analyse le message de l'utilisateur et d√©termine:
    1. La cat√©gorie (suivi, tarifs, documentation, support, g√©n√©ral)
    2. L'intention (question, demande, plainte, compliment)
    3. Le niveau de confiance (0-1)
    
    R√©ponds uniquement en JSON avec cette structure:
    {
      "category": "string",
      "intent": "string", 
      "confidence": number
    }`

    const messages: ChatMessage[] = [
      { role: 'user', content: message }
    ]

    try {
      const response = await this.generateChatCompletion(messages, {
        systemPrompt,
        temperature: 0.3,
        maxTokens: 100
      })

      return JSON.parse(response)
    } catch (error) {
      return {
        category: 'g√©n√©ral',
        intent: 'question',
        confidence: 0.5
      }
    }
  }
}

export default OpenAIService.getInstance()
